# daily_report_kline_volume.py
import os
import sys
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Tuple, Union

import pymysql
from utils import load_config, init_db

# --- é€šçŸ¥æ¨¡å—ï¼šTeamsï¼ˆå¿…æœ‰ï¼Œä¸å­˜åœ¨å°±ä¸æŠ¥é”™ï¼‰ ---
try:
    from teams_alerter import send_teams_alert
except ImportError:
    def send_teams_alert(*args, **kwargs):
        logging.getLogger('monitor_system').warning("teams_alerter æœªæ‰¾åˆ°ï¼Œè·³è¿‡ Teams å‘é€ã€‚")

# --- ä¿ç•™ï¼šLarkï¼ˆå¯é€‰ï¼‰ ---
try:
    from lark_alerter import send_lark_alert
except ImportError:
    def send_lark_alert(*args, **kwargs):
        logging.getLogger('monitor_system').warning("lark_alerter æœªæ‰¾åˆ°ï¼Œè·³è¿‡ Lark å‘é€ã€‚")

logger = logging.getLogger('monitor_system')

# ---------- æ—¥å¿— ----------
def setup_logging():
    if logger.handlers:
        return
    logger.setLevel(logging.INFO)
    fmt = logging.Formatter(
        '%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    ch = logging.StreamHandler(sys.stdout); ch.setLevel(logging.INFO); ch.setFormatter(fmt)
    log_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'daily_report_log.log')
    fh = logging.FileHandler(log_file, encoding='utf-8'); fh.setLevel(logging.INFO); fh.setFormatter(fmt)
    root = logging.getLogger('monitor_system'); root.addHandler(ch); root.addHandler(fh); root.setLevel(logging.INFO)

# ---------- å·¥å…· ----------
Number = Union[int, float]
TS = Union[int, float, datetime]

def _ci_get(d: dict, key: str):
    if not isinstance(d, dict):
        return None, None
    t = key.strip().lower()
    for k, v in d.items():
        if isinstance(k, str) and k.strip().lower() == t:
            return v, k
    return None, None

def _to_float(x) -> float:
    try:
        return float(x)
    except Exception:
        return 0.0

def _fmt_pct(x: float) -> str:
    try:
        return f"{x:+.2%}"
    except Exception:
        return "N/A"

def _fmt_ts(ts: TS) -> str:
    if isinstance(ts, datetime):
        return ts.astimezone(timezone.utc).strftime('%Y-%m-%d %H:%M')
    try:
        return datetime.utcfromtimestamp(_to_float(ts)/1000.0).strftime('%Y-%m-%d %H:%M')
    except Exception:
        return "N/A"

# ---------- æ—¶é—´æˆ³æ¨¡å¼ ----------
class TsMode:
    MS_INT = "ms_int"
    DATETIME = "datetime"

def detect_ts_mode(conn, table: str) -> str:
    sql = f"SELECT timestamp FROM {table} ORDER BY timestamp DESC LIMIT 1"
    with conn.cursor() as c:
        c.execute(sql)
        row = c.fetchone()
    if not row:
        return TsMode.MS_INT
    ts = row[0] if isinstance(row, (list, tuple)) else row.get('timestamp')
    return TsMode.DATETIME if isinstance(ts, datetime) else TsMode.MS_INT

def make_range_predicate(ts_mode: str, start_utc: datetime, end_utc: datetime):
    if ts_mode == TsMode.MS_INT:
        start_ms = int(start_utc.timestamp()*1000)
        end_ms   = int(end_utc.timestamp()*1000)
        return "timestamp >= %s AND timestamp < %s", (start_ms, end_ms)
    else:
        return "timestamp >= %s AND timestamp < %s", (start_utc, end_utc)

# ---------- é…ç½®è¯»å– ----------
def read_price_thresholds(config: dict, symbol: str) -> Dict[str, float]:
    """è¯»å–å››ä»·åå·®é˜ˆå€¼ï¼ˆç›¸å¯¹Bï¼‰ï¼šæ”¯æŒå…¨å±€ + æŒ‰æ ‡çš„è¦†ç›–"""
    ac = (config or {}).get('ALERT_CONFIG', {}) or {}
    sym_map = _ci_get(ac, 'SYMBOL_THRESHOLDS')[0] or {}
    sym_conf = sym_map.get(symbol) or {}
    def pick(name: str, default: float) -> float:
        sv, _ = _ci_get(sym_conf, name); gv, _ = _ci_get(ac, name)
        val = sv if sv is not None else (gv if gv is not None else default)
        try:
            return float(val)
        except Exception:
            return default
    return {
        "OPEN":  pick('OPEN_DEVIATION_THRESHOLD',  0.002),
        "HIGH":  pick('HIGH_DEVIATION_THRESHOLD',  0.001),
        "LOW":   pick('LOW_DEVIATION_THRESHOLD',   0.001),
        "CLOSE": pick('CLOSE_DEVIATION_THRESHOLD', 0.0005),
    }

def read_volume_params(config: dict, symbol: str) -> Tuple[float, float]:
    """è¯»å–æˆäº¤é‡ç›®æ ‡ç³»æ•°ä¸å®¹å·®ï¼šæ”¯æŒå…¨å±€ + æŒ‰æ ‡çš„è¦†ç›–"""
    ac = (config or {}).get('ALERT_CONFIG', {}) or {}
    sym_map = _ci_get(ac, 'SYMBOL_THRESHOLDS')[0] or {}
    sym_conf = sym_map.get(symbol) or {}
    tr_sym, _ = _ci_get(sym_conf, 'VOLUME_TARGET_RATIO')
    tr_glb, _ = _ci_get(ac,       'VOLUME_TARGET_RATIO')
    target_ratio = tr_sym if tr_sym is not None else (tr_glb if tr_glb is not None else 0.20)
    tol_sym, _ = _ci_get(sym_conf, 'VOLUME_RATIO_THRESHOLD')
    tol_glb, _ = _ci_get(ac,       'VOLUME_RATIO_THRESHOLD')
    tolerance = tol_sym if tol_sym is not None else (tol_glb if tol_glb is not None else 0.20)
    try:
        target_ratio = float(target_ratio)
    except Exception:
        target_ratio = 0.20
    try:
        tolerance = float(tolerance)
    except Exception:
        tolerance = 0.20
    return target_ratio, tolerance

# ---------- DB æ‹‰å– ----------
def fetch_ohlc_in_range(conn, table: str, symbol: str, exchange: str,
                        ts_mode: str, start_utc: datetime, end_utc: datetime) -> List[dict]:
    where, params = make_range_predicate(ts_mode, start_utc, end_utc)
    sql = f"""
        SELECT timestamp, `open`, `high`, `low`, `close`, volume
        FROM {table}
        WHERE symbol=%s AND exchange=%s AND {where}
        ORDER BY timestamp ASC
    """
    args = (symbol, exchange, *params)
    with conn.cursor(cursor=pymysql.cursors.DictCursor) as c:
        c.execute(sql, args)
        return c.fetchall() or []

# ---------- ç»Ÿè®¡ ----------
def aggregate_daily_for_symbol(rows_a: List[dict], rows_b: List[dict],
                               price_thresholds: Dict[str, float],
                               volume_target_ratio: float):
    """
    price_stats: {'counts':{O,H,L,C}, 'exceeds':[{ts,field,a,b,abs,rel}, ...]}
    volume_stats: {'A_sum','B_sum','target','diff_abs','diff_rel'}
    """
    map_a = {r['timestamp']: r for r in rows_a}
    map_b = {r['timestamp']: r for r in rows_b}
    commons = sorted(set(map_a.keys()) & set(map_b.keys()))

    counts = {'OPEN':0, 'HIGH':0, 'LOW':0, 'CLOSE':0}
    exceeds: List[dict] = []

    def check(field_key: str, a_val: Number, b_val: Number, thr: float, ts: TS):
        if b_val is None or _to_float(b_val) == 0.0:
            return
        rel = abs(_to_float(a_val) - _to_float(b_val)) / abs(_to_float(b_val))
        if rel > thr:
            counts[field_key] += 1
            exceeds.append({
                'ts': ts, 'field': field_key,
                'a': _to_float(a_val), 'b': _to_float(b_val),
                'abs': _to_float(a_val) - _to_float(b_val),
                'rel': rel
            })

    for ts in commons:
        ra = map_a[ts]; rb = map_b[ts]
        check('OPEN',  ra['open'],  rb['open'],  price_thresholds['OPEN'],  ts)
        check('HIGH',  ra['high'],  rb['high'],  price_thresholds['HIGH'],  ts)
        check('LOW',   ra['low'],   rb['low'],   price_thresholds['LOW'],   ts)
        check('CLOSE', ra['close'], rb['close'], price_thresholds['CLOSE'], ts)

    A_sum = sum(_to_float(map_a[ts]['volume']) for ts in commons)
    B_sum = sum(_to_float(map_b[ts]['volume']) for ts in commons)
    target = volume_target_ratio * B_sum
    diff_abs = A_sum - target
    diff_rel = (diff_abs / target) if target != 0 else (0.0 if diff_abs == 0 else float('inf'))

    price_stats = {'counts': counts, 'exceeds': exceeds}
    volume_stats = {'A_sum': A_sum, 'B_sum': B_sum, 'target': target, 'diff_abs': diff_abs, 'diff_rel': diff_rel}
    return price_stats, volume_stats

# ---------- Markdown æŠ¥å‘Š ----------
def render_markdown(report_date_str: str, timeframe: str,
                    start_utc: datetime, end_utc: datetime,
                    per_symbol: Dict[str, dict]) -> str:
    lines: List[str] = []
    lines.append(f"# ç›‘æ§æ—¥æŠ¥ï¼ˆUTCï¼‰ - {report_date_str}")
    lines.append("")
    lines.append(f"- ç»Ÿè®¡åŒºé—´ï¼š{start_utc.strftime('%Y-%m-%d %H:%M')} ~ {end_utc.strftime('%Y-%m-%d %H:%M')} UTC")
    lines.append(f"- æ—¶é—´ç²’åº¦ï¼š{timeframe}")
    lines.append("")

    total_price_exceeds = 0
    for _, d in per_symbol.items():
        c = d['price']['counts']
        total_price_exceeds += (c['OPEN'] + c['HIGH'] + c['LOW'] + c['CLOSE'])
    lines.append(f"**å…¨é‡æ±‡æ€»ï¼šå››ä»·è¶Šé˜ˆæ€»æ¬¡æ•° = {total_price_exceeds}**")
    lines.append("")

    for sym, d in per_symbol.items():
        price = d['price']; vol = d['volume']; c = price['counts']
        lines.append(f"## {sym}")
        lines.append("")
        lines.append(f"**å››ä»·è¶Šé˜ˆæ¬¡æ•°**ï¼šOPEN={c['OPEN']} | HIGH={c['HIGH']} | LOW={c['LOW']} | CLOSE={c['CLOSE']}")
        lines.append("")
        if price['exceeds']:
            lines.append("<details><summary>æ˜ç»†ï¼ˆå…¨éƒ¨è¶Šé˜ˆç‚¹ï¼‰</summary>")
            lines.append("")
            lines.append("| æ—¶é—´(UTC) | å­—æ®µ | Aå€¼ | Bå€¼ | ç»å¯¹åå·® | ç›¸å¯¹åå·® |")
            lines.append("|---|---|---:|---:|---:|---:|")
            for item in price['exceeds']:
                lines.append(f"| {_fmt_ts(item['ts'])} | {item['field']} | "
                             f"{item['a']:.6g} | {item['b']:.6g} | {item['abs']:.6g} | {_fmt_pct(item['rel'])} |")
            lines.append("")
            lines.append("</details>")
        else:
            lines.append("_å››ä»·å‡æœªè¶Šé˜ˆã€‚_")
        lines.append("")
        lines.append("**æˆäº¤é‡ï¼ˆæŒ‰å¤©ç´¯è®¡ï¼‰**")
        lines.append("")
        lines.append(f"- A ç´¯è®¡æˆäº¤é‡ï¼š{vol['A_sum']:.6f}")
        lines.append(f"- B ç´¯è®¡æˆäº¤é‡ï¼š{vol['B_sum']:.6f}")
        lines.append(f"- ç›®æ ‡ï¼ˆrÃ—Bï¼‰ï¼š{vol['target']:.6f}")
        lines.append(f"- åå·®ï¼ˆç»å¯¹ï¼‰ï¼š{vol['diff_abs']:.6f}")
        lines.append(f"- åå·®ï¼ˆç›¸å¯¹ï¼‰ï¼š{_fmt_pct(vol['diff_rel'])}")
        lines.append("")
    return "\n".join(lines)

# ---------- é£ä¹¦/Teams æ‘˜è¦ï¼ˆå…¨é‡æ ‡çš„ï¼Œè‡ªåŠ¨åˆ†æ¡ï¼‰ ----------
def render_summary_chunks(report_date_str: str,
                          start_utc: datetime, end_utc: datetime,
                          per_symbol: Dict[str, dict],
                          max_chars: int = 2500) -> List[Tuple[str, str]]:
    """
    ç”Ÿæˆã€å¤šæ¡ã€‘æ‘˜è¦ï¼ˆè¦†ç›–æ‰€æœ‰æ ‡çš„ï¼Œä¸æˆªæ–­ï¼‰ã€‚
    æ¯æ¡æ¶ˆæ¯ <= max_charsï¼ˆç²—ç•¥æ§åˆ¶ï¼‰ï¼Œä¾æ¬¡å‘é€ã€‚
    è¿”å› [(title, text), ...]
    """
    total_price_ex = 0
    vol_exceed_count = 0
    exceed_lines: List[str] = []
    normal_lines: List[str] = []

    for sym, d in per_symbol.items():
        c = d['price']['counts']
        total_ex_sym = c['OPEN'] + c['HIGH'] + c['LOW'] + c['CLOSE']
        total_price_ex += total_ex_sym

        vol = d['volume']
        r   = d['volume_ratio']
        tol = d['volume_tolerance']
        dev = vol['diff_rel']
        dev_str = _fmt_pct(dev)

        line = f"[{total_ex_sym}] {sym}: O={c['OPEN']} H={c['HIGH']} L={c['LOW']} C={c['CLOSE']} | Vol dev={dev_str} (r={r:.2f})"
        if abs(dev) > tol:
            line += " ã€EXCEEDã€‘"
            exceed_lines.append(line)
            vol_exceed_count += 1
        else:
            normal_lines.append(line)

    lines_all: List[str] = []
    lines_all.extend(exceed_lines)
    lines_all.extend(normal_lines)

    header_full = (
        f"æ—¶é—´ï¼š{start_utc.strftime('%Y-%m-%d %H:%M')} ~ {end_utc.strftime('%Y-%m-%d %H:%M')} UTC\n"
        f"æ ‡çš„æ•°ï¼š{len(per_symbol)}\n"
        f"å››ä»·è¶Šé˜ˆæ€»æ¬¡æ•°ï¼š{total_price_ex}\n"
        f"æˆäº¤é‡è¶…é˜ˆæ ‡çš„æ•°ï¼š{vol_exceed_count}\n\n"
    )
    header_cont = "ï¼ˆç»­ï¼‰ä»¥ä¸‹ä¸ºå…¶ä½™æ ‡çš„ç»Ÿè®¡ï¼š\n\n"

    chunks: List[Tuple[str, str]] = []
    acc_lines: List[str] = []
    acc_len = 0

    def flush_chunk(idx: int, total: int, is_first: bool):
        nonlocal acc_lines
        if not acc_lines:
            return
        title = f"ğŸ“Š æ—¥æŠ¥ï¼ˆKçº¿+æˆäº¤é‡ç»Ÿè®¡ï¼‰UTC {report_date_str}ï¼ˆ{idx}/{total}ï¼‰"
        head = header_full if is_first else header_cont
        body = head + "\n".join(acc_lines)
        chunks.append((title, body))
        acc_lines = []

    for line in lines_all:
        delta = len(line) + 1
        reserve = 600 if not chunks else 200
        if (acc_len + delta + reserve) > max_chars and acc_lines:
            flush_chunk(idx=len(chunks)+1, total=9999, is_first=(len(chunks)==0))
            acc_len = 0
        acc_lines.append(line)
        acc_len += delta

    if acc_lines:
        flush_chunk(idx=len(chunks)+1, total=9999, is_first=(len(chunks)==0))

    fixed: List[Tuple[str, str]] = []
    total_n = len(chunks)
    for i, (title, body) in enumerate(chunks, 1):
        new_title = title.rsplit('ï¼ˆ', 1)[0] + f"ï¼ˆ{i}/{total_n}ï¼‰"
        fixed.append((new_title, body))
    return fixed

# ---------- ä¸»æµç¨‹ ----------
def main():
    setup_logging()
    conn = None
    try:
        config = load_config()
        conn = init_db(config)
        try:
            conn.autocommit(True)
            with conn.cursor() as c:
                c.execute("SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED")
        except Exception:
            pass

        teams_cfg = config.get('TEAMS_NOTIFY') or {}
        lark_cfg  = config.get('LARK_APP_CONFIG') or {}

        table = (config.get('TABLE_NAMES') or {}).get('KLINE_DATA') or 'kline_data'
        ex = config.get('EXCHANGE_CONFIG') or {}
        A_ID = (ex.get('PLATFORM_A_ID') or 'BITDA_FUTURES').upper()
        B_ID = (ex.get('BENCHMARK_ID') or 'BINANCE_FUTURES').upper()
        timeframe = (ex.get('TIME_FRAME') or '1m').lower()
        symbols = (config.get('MONITORED_SYMBOLS') or (ex.get('MONITORED_SYMBOLS') or []))
        if not symbols:
            logger.critical("é…ç½®ç¼ºå°‘ MONITORED_SYMBOLSã€‚")
            return

        # UTC æ˜¨å¤©åŒºé—´
        today_utc = datetime.now(timezone.utc).date()
        start_utc = datetime.combine(today_utc - timedelta(days=1), datetime.min.time(), tzinfo=timezone.utc)
        end_utc   = datetime.combine(today_utc, datetime.min.time(), tzinfo=timezone.utc)
        report_date_str = (today_utc - timedelta(days=1)).strftime("%Y-%m-%d")

        ts_mode = detect_ts_mode(conn, table)
        logger.info(f"[æ—¥æŠ¥] æ—¶é—´èŒƒå›´ï¼ˆUTCï¼‰ï¼š{start_utc} ~ {end_utc} | ts_mode={ts_mode}")

        per_symbol: Dict[str, dict] = {}

        for sym in symbols:
            # è¯»å–é˜ˆå€¼ & æˆäº¤é‡å‚æ•°
            price_thr = read_price_thresholds(config, sym)
            vol_ratio, vol_tol = read_volume_params(config, sym)

            # é˜ˆå€¼ç¡®è®¤æ—¥å¿—
            logger.info(
                f"[{sym}] é˜ˆå€¼ç¡®è®¤ | OPEN={price_thr['OPEN']:.4%}, HIGH={price_thr['HIGH']:.4%}, "
                f"LOW={price_thr['LOW']:.4%}, CLOSE={price_thr['CLOSE']:.4%} | "
                f"VOLUME: r={vol_ratio:.2f}, tol={vol_tol:.2%}"
            )

            rows_a = fetch_ohlc_in_range(conn, table, sym, A_ID, ts_mode, start_utc, end_utc)
            rows_b = fetch_ohlc_in_range(conn, table, sym, B_ID, ts_mode, start_utc, end_utc)

            price_stats, volume_stats = aggregate_daily_for_symbol(rows_a, rows_b, price_thr, vol_ratio)
            per_symbol[sym] = {
                'price': price_stats,
                'volume': volume_stats,
                'volume_ratio': vol_ratio,
                'volume_tolerance': vol_tol,
            }

        # å†™ Markdown æ˜ç»†åˆ°å­ç›®å½• daily_report_kline_volume/
        base_dir = os.path.dirname(os.path.abspath(__file__))
        out_dir  = os.path.join(base_dir, "daily_report_kline_volume")
        os.makedirs(out_dir, exist_ok=True)
        md = render_markdown(report_date_str, timeframe, start_utc, end_utc, per_symbol)
        out_name = f"daily_report_{report_date_str}_UTC.md"
        out_path = os.path.join(out_dir, out_name)
        with open(out_path, "w", encoding="utf-8") as f:
            f.write(md)
        logger.info(f"[æ—¥æŠ¥] å·²ç”Ÿæˆï¼š{out_path}")

        # æ‘˜è¦åˆ†æ¡ â†’ å‘é€åˆ° Teamsï¼ˆä¹Ÿå¯ä¿ç•™ Lark åŒå‘ï¼‰
        chunks = render_summary_chunks(report_date_str, start_utc, end_utc, per_symbol)
        for title, text in chunks:
            try:
                send_teams_alert(teams_cfg, title, text, severity="info")
            except Exception as e:
                logger.warning(f"Teams æ‘˜è¦å‘é€å¤±è´¥ï¼š{e} | æ ‡é¢˜={title}")
            try:
                send_lark_alert(lark_cfg, title, text)
            except Exception as e:
                logger.warning(f"Lark æ‘˜è¦å‘é€å¤±è´¥ï¼š{e} | æ ‡é¢˜={title}")

    except Exception as e:
        logger.critical(f"æ—¥æŠ¥ç”Ÿæˆå¤±è´¥ï¼š{e}", exc_info=True)
    finally:
        if conn:
            try: conn.close()
            except Exception: pass
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­ã€‚")

if __name__ == "__main__":
    main()
